{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgambone3/CSC4850-Machine-Learning/blob/main/ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfWu0ODBEG09"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sklearn \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# metrics\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import mean_squared_error as MSE\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "# processing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "\n",
        "# models\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.naive_bayes import ComplementNB, MultinomialNB \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQJFgAOWxxlo"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ML_Project/Diabetes Indicators Dataset/diabetes_012_health_indicators_BRFSS2015.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC9dzWP0EPQg"
      },
      "outputs": [],
      "source": [
        "X = df.iloc[:, 1:] # features\n",
        "X = X.astype(int)\n",
        "y = df.iloc[:, :1]\n",
        "y = y.astype(int).values.ravel()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions\n",
        "\n",
        "\n",
        "*   Learning Curves\n",
        "*   Best Polynomial\n",
        "\n"
      ],
      "metadata": {
        "id": "7HjY-pK0hmit"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper function to get learning curve plot\n",
        "#### Predicts target variable at every n interval of the dataset to use as points on learning curve plot."
      ],
      "metadata": {
        "id": "wXmZQMiC-p6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_learning_curve(model, X, y, title):\n",
        "  scores=[]\n",
        "  perc=[]\n",
        "  for n in range(1,101):\n",
        "    perc.append(n)\n",
        "    XX = X.iloc[0:int(len(X) * (n/100))] #df\n",
        "    yy = y[0:int(len(y) * (n/100))] #list\n",
        "    pred = model.predict(XX)\n",
        "    score = MSE(y_true=yy, y_pred=pred)\n",
        "    scores.append(score)\n",
        "  return pd.DataFrame({'percent':perc, 'scores':scores})"
      ],
      "metadata": {
        "id": "7QJNdAZi-odS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helper function to find best polynomial for linear regression"
      ],
      "metadata": {
        "id": "T5AHAbaS-cwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def best_poly(X_train, y_train, X_test, y_test):\n",
        "  degree = [1, 2]\n",
        "  z = []\n",
        "  poly_df = pd.DataFrame(columns=['polynomial', 'score'])\n",
        "  print('   Polynomial Scores')\n",
        "  for deg in degree:\n",
        "    linreg = LinearRegression()\n",
        "    polynomial_features = PolynomialFeatures(degree=deg,\n",
        "                                             include_bias=False)\n",
        "    lin_pipe = Pipeline([('scaler', MinMaxScaler()),\n",
        "                        (\"polynomial_features\", polynomial_features),\n",
        "                        (\"linear_regression\", linreg)])\n",
        "    lin_pipe.fit(X,y)\n",
        "    score = lin_pipe.score(X_test,y_test)\n",
        "    z.append(score)\n",
        "    print(f'Degree: {deg}  Score: {score}')\n",
        "  p = z.index(max(z)) + 1\n",
        "    \n",
        "  return p "
      ],
      "metadata": {
        "id": "tbUHcZTP-dbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split original data into three seperate ratios\n",
        "#### Splitting data outside of loop for cohesion. This way assures the same data points are used for all the splits on all the models. \n",
        "#### Initialize dataframe labels and plot colors\n",
        "\n"
      ],
      "metadata": {
        "id": "kRBBQMBa_KsJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jTGZTEoK0MA"
      },
      "outputs": [],
      "source": [
        "# X_train_temp, X_test_temp, y_train_temp, y_test_temp = train_test_split(X, y,train_size=0.20)\n",
        "# Create all three splits outside of loop to run each model on same data splits\n",
        "X55_train, X55_test, y55_train, y55_test = train_test_split(X, \n",
        "                                                            y, \n",
        "                                                            train_size=.5, \n",
        "                                                            test_size=.5, \n",
        "                                                            shuffle=True,\n",
        "                                                            random_state=1234)\n",
        "X73_train, X73_test, y73_train, y73_test = train_test_split(X, \n",
        "                                                            y, \n",
        "                                                            train_size=.7, \n",
        "                                                            test_size=.3, \n",
        "                                                            shuffle=True,\n",
        "                                                            random_state=1234)\n",
        "X82_train, X82_test, y82_train, y82_test = train_test_split(X, \n",
        "                                                            y, \n",
        "                                                            train_size=.8, \n",
        "                                                            test_size=.2, \n",
        "                                                            shuffle=True,\n",
        "                                                            random_state=1234)\n",
        "# List of train and test motels to access later in loop\n",
        "train = [(X55_train, y55_train), \n",
        "         (X73_train, y73_train), \n",
        "         (X82_train, y82_train)]\n",
        "test = [(X55_test, y55_test),\n",
        "        (X73_test, y73_test),\n",
        "        (X82_test, y82_test)]\n",
        "\n",
        "# initialize lists of color for plots\n",
        "train_colors = ['navy', 'green', 'firebrick']\n",
        "test_colors = ['skyblue', 'palegreen', 'salmon']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialize models"
      ],
      "metadata": {
        "id": "wv1D4DkF_rVH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ExBXcEmY5Fb"
      },
      "outputs": [],
      "source": [
        "titles = ['Decision Tree Classifier',\n",
        "          'Perceptron',\n",
        "          'Compliment Naive Bayes',\n",
        "          'Multinomial Naive Bayes',\n",
        "          'Logistic Regression',\n",
        "          'Linear Regression',\n",
        "          'SVM - Linear',\n",
        "          'SVM - RBF',\n",
        "          'Gradient Boost',\n",
        "          'Muti-Layer Perceptron',\n",
        "          'Regularilized Linear Regression',\n",
        "          'Lasso Linear Regression',\n",
        "          'k-Nearest Neighbors',\n",
        "          'Linear Regression with Optimal Polynomial']\n",
        "\n",
        "models = [DecisionTreeClassifier(criterion='entropy', splitter='best'),\n",
        "          Perceptron(class_weight='balanced'),\n",
        "          ComplementNB(),\n",
        "          MultinomialNB (),\n",
        "          LogisticRegression(class_weight='balanced'), \n",
        "          LinearRegression(),\n",
        "          LinearSVC(class_weight='balanced', dual=False),\n",
        "          SVC(kernel='rbf', decision_function_shape='ovr'),\n",
        "          GradientBoostingClassifier(),\n",
        "          MLPClassifier(max_iter=500, hidden_layer_sizes=10),\n",
        "          SGDRegressor(loss='squared_error', penalty='l2'),\n",
        "          Lasso(selection='random'),\n",
        "          KNeighborsClassifier(weights='distance'),\n",
        "          LinearRegression()]\n",
        "\n",
        "# list of split ratios to output onto plots\n",
        "splits = [(0.5, 0.5), \n",
        "          (0.7, 0.3),\n",
        "          (0.8, 0.2)]\n",
        "\n",
        "# create labels for fold metrics dataframe\n",
        "index = []\n",
        "for i in range(1,11):\n",
        "  index.append(f'Fold {i}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipeline\n",
        "\n",
        "This cell holds a nested loop which performs multiple steps to initiialize the models, get their model metrics, output learning curves, etc. Outputs for metrics of each fold, and split are generated.\n",
        "\n",
        "\n",
        "1. for each model\n",
        "*   scale the data\n",
        "2. for each split on the model\n",
        "*   fit the pipeline\n",
        "\n",
        "*   10-fold cross-validation\n",
        "\n",
        "*   calculate metrics for model performance on test data\n",
        "\n",
        "*   generate and output learning curves wiht one plot for each model, and all splits on that one plot. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TjaYGh8U_3FJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "# dataframe to store all split information, will be used to pick the best splits\n",
        "splits_df = pd.DataFrame(columns=['Model', \n",
        "                                  'Split', \n",
        "                                  'Error',  \n",
        "                                  'Generalization', \n",
        "                                  'true', \n",
        "                                  'pred'])\n",
        "# dataframe to hold all model and split metrics\n",
        "big_df = pd.DataFrame(columns=['Model', 'Split'])\n",
        "\n",
        "for model in models: # for each model in model list\n",
        "    # print(titles[i])\n",
        "    pipe = make_pipeline(MinMaxScaler(), model) # make pipeline with steps to use MinMaxScaler to [0,1]\n",
        "    # for plotting learning curves\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    # dataframe to hold and output all metridcs for every split on model\n",
        "    fold_df = pd.DataFrame(columns=['Accuracy',\n",
        "                                    'Precision', \n",
        "                                    'Recall', \n",
        "                                    'F1-Score', \n",
        "                                    'R2'\n",
        "                                    'Error'],\n",
        "                                    index=index)\n",
        "    j=0\n",
        "    for j in range(len(splits)): # for each data split\n",
        "      # rename variables for test/train data, based on list of tuples in previous cell\n",
        "      X_train = train[j][0]\n",
        "      y_train = train[j][1]\n",
        "      X_test = test[j][0]\n",
        "      y_test = test[j][1]\n",
        "\n",
        "      # condition to call polynomial function only on this model type\n",
        "      if 'Polynomial' in titles[i]:\n",
        "        poly_df = pd.DataFrame(columns=['polynomial', 'score'])\n",
        "        poly = best_poly(X_train, y_train, X_test, y_test)       \n",
        "        pipe = make_pipeline(MinMaxScaler(),\n",
        "                             PolynomialFeatures(degree=poly),\n",
        "                             LinearRegression())\n",
        "      # fit data to the training dataset\n",
        "      pipe.fit(X_train, y_train)\n",
        "      \n",
        "      # print(splits[j])\n",
        "      # conduct 10-fold cross validation with specific scores\n",
        "      cv = cross_validate(pipe, \n",
        "                          X_train, \n",
        "                          y_train,\n",
        "                          scoring=['accuracy', \n",
        "                                    'precision_weighted',\n",
        "                                    'recall_weighted',\n",
        "                                    'f1_weighted',\n",
        "                                    'r2',\n",
        "                                    'neg_mean_squared_error'], \n",
        "                          cv=10) \n",
        "      # variable to hold predicted values on test set\n",
        "      pred = pipe.predict(X_test)\n",
        "      # calculate test error on test set\n",
        "      test_error = MSE(y_test, pred)\n",
        "\n",
        "      # adding absolute value of neg mean squared error so lower error is better, \n",
        "      # while CV uses neg_MSE to follow convention of all other metrics that higher is better\n",
        "      # concat metrics to dataframe\n",
        "      fold_df = pd.concat({'Accuracy':pd.Series(cv['test_accuracy']), \n",
        "                            'Precision':pd.Series(cv['test_precision_weighted']),\n",
        "                            'Recall':pd.Series(cv['test_recall_weighted']),\n",
        "                            'F1-Score':pd.Series(cv['test_f1_weighted']),\n",
        "                            'R2' : pd.Series(cv['test_r2']),\n",
        "                            'Error':pd.Series(abs(cv['test_neg_mean_squared_error']))},\n",
        "                            axis=1)\n",
        "      # add metrics to best splits dataframe, generalization is calculated from the difference between test and train errors\n",
        "      splits_df.loc[len(splits_df)] = [titles[i], \n",
        "                                      splits[j], \n",
        "                                      fold_df['Error'].min(),\n",
        "                                      abs(fold_df['Error'].min() - test_error),\n",
        "                                      test[j][1],\n",
        "                                      pred]\n",
        "      # concat data to big dataframe for final output\n",
        "      big_df = pd.concat([big_df, fold_df], ignore_index=True, axis=0)\n",
        "      # add split identification to rows all 10 rows of the cross validation fold\n",
        "      big_df['Split'].iloc[((i*30)+(j*10)):((i*30)+(j*10)+10)] = str(splits[j])\n",
        "      \n",
        "      fold_df.index = index # set index for visualation purposes\n",
        "      # create display caption for fold dataframe, for visualization purposes\n",
        "      fold_disp = fold_df.style.set_caption(f'Fold Metrics for {titles[i]} with {int(splits[j][0] * 100)}/{int(splits[j][1]*100)} Split')\n",
        "      # print('\\n')\n",
        "      display(fold_disp) # display fold metrics\n",
        "      \n",
        "      # PLOT LEARNING CURVES\n",
        "      # get training and testing scores by calling learning curve function\n",
        "      train_scores = get_learning_curve(pipe, X_train, y_train, titles[i])\n",
        "      test_scores = get_learning_curve(pipe, X_test, y_test, titles[i])\n",
        "      # plot training scores\n",
        "      ax.plot(train_scores['percent'], \n",
        "              train_scores['scores'], \n",
        "              color=train_colors[j],\n",
        "              label=f'{int(splits[j][0] * 100)}/{int(splits[j][1]*100)} Training')\n",
        "      # plot testing scores\n",
        "      ax.plot(test_scores['percent'], \n",
        "              test_scores['scores'],  \n",
        "              color=test_colors[j],\n",
        "              label=f'{int(splits[j][0] * 100)}/{int(splits[j][1]*100)} Validation')\n",
        "      # set labeles and titles\n",
        "      ax.set_xlabel('Sample Size')\n",
        "      ax.set_ylabel('Error')\n",
        "      ax.set_title(f'Learning Curve for {titles[i]}')\n",
        "      ax.legend(loc='best')\n",
        "      fig.tight_layout(pad=1.5)\n",
        "      fig.show()\n",
        "      j += 1 # increment to next split\n",
        "    # add model name to all 30 fold metrics (10 + 10 + 10 -> 10 folds, 3 splits, 1 model)\n",
        "    big_df['Model'].iloc[(i*30):((i*30)+30)] = titles[i]\n",
        "    i+=1  # increment to next fold\n",
        "    \n"
      ],
      "metadata": {
        "id": "NmRdVjKFotXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, split_df holds the metrics for the best fold for each split, so there are three rows for every model, one for each split (50/50, 70/30, 80/20) for a total of (15models * 3splits).\n",
        "\n",
        "The following cell selects the *best split* based on all the best folds for each model, which was selected in the previous cell. The dataframe groups by model name, and selects the split for each model based on which of the three has the lowest error. "
      ],
      "metadata": {
        "id": "l95K_syF1rl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best = (splits_df.loc[splits_df.groupby('Model', sort=False)['Error'].idxmin()])\n",
        "display(best)"
      ],
      "metadata": {
        "id": "SNfDKtWa1juI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generating Confusion Matrix\n",
        "This cell generates and outputs the Confusion Matricies for all applicable models. If 'Linear Regression' is in the model name, the function is skipped as confusion matricies are not applicable for continuious values. "
      ],
      "metadata": {
        "id": "z8mcfVdg2xox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loop to generate confusion matrix\n",
        "for b in range(len(best)):\n",
        "  # skip models with Linear Regression in the title because cannot calculate confision matrix for continuious values\n",
        "  if 'Linear Regression' not in best.iloc[b]['Model']:\n",
        "    ConfusionMatrixDisplay.from_predictions(y_true=best.iloc[b]['true'], \n",
        "                                            y_pred=best.iloc[b]['pred'],\n",
        "                                            cmap='RdPu')\n",
        "    # set titles\n",
        "    title=best.iloc[b]['Model']\n",
        "    plt.title(f'Confusion Matrix for {title}')\n",
        "    plt.show()\n",
        "  else:\n",
        "    # output confirmation that regression model was skipped\n",
        "    print('Cannot calculate Confusion Matrix for Regression Problems - ', titles[b])"
      ],
      "metadata": {
        "id": "51P__X121lo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selecting columns to display for the dataframe with all the best models. This dataframe holds one row for each model, indicating the best split, for each model, based on the best fold for that split, with the lowest MSE."
      ],
      "metadata": {
        "id": "s7rjM7tp3Ioy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop columns with y_true and y_pred that were used to generate matrix\n",
        "best = best.drop(['true', 'pred'], axis=1)\n",
        "\n",
        "# adjust dataframe for better display\n",
        "best.reset_index(inplace=True, drop=True) \n",
        "disp_best = best.style.set_caption(f'Best Split for Each Model')\n",
        "display(disp_best)"
      ],
      "metadata": {
        "id": "LANLn7IN1niI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display big_df with every metric for every model, for ever split. "
      ],
      "metadata": {
        "id": "9kTOk3fa3WUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#output big_df with all metrics for every model, on every split\n",
        "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
        "    display(big_df)"
      ],
      "metadata": {
        "id": "zdZKh-jx1orD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1zOyzhtaV7CsWKf-qvHTkAxHmbqnqDd2D",
      "authorship_tag": "ABX9TyMqruoOdQAtzE8ubF+nbAJ0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}